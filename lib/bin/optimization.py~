#python default modules
import numpy as np
import scipy as sp
import scipy.stats as stats
from scipy.optimize import minimize
import os, sys, re, threading, subprocess, time
from sklearn.preprocessing import PolynomialFeatures
from collections import OrderedDict
import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.rc('figure', max_open_warning = 0)
from scipy.linalg import block_diag
import json
import yaml
#program specific modules

import make_input_file
import FlameMaster_in_parallel
import combustion_dataset_class
import combustion_variable_class
import combustion_target_class
import data_management
import simulation_manager
import uncertainty
import MechanismManipulator
import plotter
import Input_file_reader


### KEY WORDS #######
optType = "optimization_type"
targets = "targets"
mech = "mechanism"
pre_file = "Initial_pre_file"
count = "Counts"
countTar = "targets_count"
home_dir = os.getcwd()
fuel = "fuel/s"
fuelClass = "fuelClass"
bin_solve = "solver_bin"
bin_opt = "bin"
globRxn = "global_reaction"
countThreads = "parallel_threads"
unsrt = "uncertainty_data"
thermoF = "thermo_file"
transF = "trans_file"
order = "Order_of_PRS"
startProfile = "StartProfilesData"
design = "Design_of_PRS"
countRxn = "total_reactions"
fT = "fileType"
add = "addendum"
###########
#open the input file and check for arguements
###########

if len(sys.argv) > 1:
	input_file = open(sys.argv[1],'r')
	optInputs = yaml.safe_load(input_file)
	print("Input file found\n")
else:
	print("Please enter a valid input file name as arguement. \n For details of preparing the input file, please see the UserManual\n\nProgram exiting")
	exit()

#!!!!!!! GET MECHANISM FILE , number of targets  from the input file !!!!!!!!!

dataCounts = optInputs[count]
binLoc = optInputs["Bin"]
inputs = optInputs["Inputs"]
locations = optInputs["Locations"]
startProfile_location = optInputs[startProfile]
stats = optInputs["Stats"]
unsrt_location = locations[unsrt]
mech_file_location = locations[mech]
thermo_file_location = locations[thermoF]
trans_file_location = locations[transF]
fileType = inputs[fT]
if fileType == "chemkin":
	file_specific_input = "-f chemkin"
else:
	file_specific_input = ""
fuel = inputs[fuel]
global_reaction = inputs[globRxn]
design_type = stats[design]
parallel_threads = dataCounts[countThreads]
rps_order = stats[order]

targetLines = open(locations[targets],'r').readlines()
addendum = yaml.safe_load(locations[add])
##!!!  MAKE A LIST OF TARGET CLASS CONTAINING EACH TARGET AS A CASE
def filter_list(List):
	temp = []
	for i in List:
		if i != "":
			temp.append(i)
	return temp
target_list = []
c_index = 0
for target in targetLines:
	if "#" in target:
		target = target[:target.index('#')]	
	t = combustion_target_class.combustion_target(target,addendum,c_index)
	c_index +=1
	target_list.append(t)
case_dir = range(0,len(target_list))
print("optimization targets identified\n")

##########Obtain uncertainty data from user input file!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

UncertDataSet = uncertainty.uncertaintyData(unsrt_location,mech_file_location,thermo_file_location,trans_file_location);
unsrt_data,rxnUnsrt_data,focUnsrt_data,tbdUnsrt_data,thermoUnsrt_data,transportUnsrt_data, reaction_index,fallOffCurve_index, thirdBody_index, thermo_index, transport_index = UncertDataSet.extract_uncertainty();
BranchingRxns = []
#pDeptRxns=[]
activeParameters = []
unsrtDatabase = {}
thirdBody_dict = {}
total_m_params = []                                                   

for index,rxn in enumerate(reaction_index):
	branch_bool = rxnUnsrt_data[rxn].branching
	if branch_bool.strip() == "True":
		BranchingRxns.append(rxnUnsrt_data[rxn].branches.split(",")) 
	activeParameters.append(rxn)
	unsrtDatabase[rxn] = unsrt_data[rxn].getDtList()

for i in fallOffCurve_index:
	activeParameters.append(i)
	unsrtDatabase[i] = unsrt_data[i].getDtList()

for i in thirdBody_index:
	activeParameters.append(i)
	unsrtDatabase[i] = unsrt_data[i].getDtList()
	temp = []
	for j in unsrt_data[i].branches.split(","):
		temp.append(j)
	thirdBody_dict[i] = temp
	total_m_params.append(temp)
	
for i in thermo_index:
	activeParameters.append(i)
	unsrtDatabase[i] = unsrt_data[i].getDtList()

for i in transport_index:
	activeParameters.append(i)
	unsrtDatabase[i] = unsrt_data[i].getDtList()

print("Uncertainty data acquired \n")


########### DO SENSITIVITY ANALYSIS ######################!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# CREATE reaction list


if "SA" not in os.listdir():
	os.mkdir("SA")
	os.chdir("SA")
	sensDir = os.getcwd()
	os.mkdir("Data")
	os.chdir("Data")
	os.mkdir("NumericalAnalysis")
	os.mkdir("ResponseSurface")
	os.mkdir("Simulations")
	os.chdir("..")
	os.mkdir("Plots")
	os.chdir("Plots")
	os.mkdir("SingularValues")
	os.chdir("..")
else:
	os.chdir("SA")
	
	sensDir = os.getcwd()

#################################################################################
########           SIMULATIONS              #####################################
########              FOR                   #####################################
########        SENSITIVITY ANALYSIS        #####################################
#################################################################################


sim_type = 'sa'
manipulation_dict = {}

if os.path.isfile("progress") == False:
	FlameMaster_Execution_location,sa_manipulation_dict = simulation_manager.SM(case_dir,rps_order,activeParameters, reaction_index,fallOffCurve_index, thirdBody_index, thermo_index, transport_index, mech_file_location, fileType, rxnUnsrt_data, focUnsrt_data,tbdUnsrt_data, thermoUnsrt_data, transportUnsrt_data, target_list, fuel, global_reaction, thermo_file_location, trans_file_location,startProfile_location,design_type,sim_type,parallel_threads).make_directories_for_simulation()	
	locations = open(sensDir+"/locations",'w')
	mani_list = open(sensDir+"/manipulation_list",'w')
	mani_key  = open(sensDir+"/manipulation_key",'w')
	for i in sa_manipulation_dict:
		mani_key.write(i+'\n')
	mani_list.write(str(sa_manipulation_dict))
	for i in FlameMaster_Execution_location:
		locations.write(i+'\n')
	locations.close()
	mani_key.close()
	mani_list.close()
	FlameMaster_in_parallel.run_FlameMaster_parallel(FlameMaster_Execution_location, parallel_threads, thermo_file_location, trans_file_location,startProfile_location,file_specific_input)
else:
	sa_manipulation_dict = {}
	progress = open(sensDir+"/progress",'r').readlines()
	manipulation_list = open(sensDir+"/manipulation_list",'r').read().replace("\'","\"")
	sa_manipulation_dict  = json.loads(manipulation_list)
	#manipulation_list = manipulation_list.strip("\"").split("\n")
	#print(manipulation_list)
	#manipulation_list = dict(filter_list(manipulation_list))
	#manipulation_key = open(sensDir+"/manipulation_key",'r').readlines()

	#for i,key in enumerate(manipulation_key):
		#print(manipulation_list[i])
	#	sa_manipulation_dict[str(key).strip()] = dict(manipulation_list[i].replace('"',''))
	FlameMaster_Execution_location = open(sensDir+"/locations",'r').readlines()
	missing_location = data_management.find_missing_location(FlameMaster_Execution_location, progress)
	FlameMaster_in_parallel.run_FlameMaster_parallel(missing_location, parallel_threads, thermo_file_location, trans_file_location,startProfile_location,file_specific_input)


manipulation_dict[sim_type] = sa_manipulation_dict

sim_dict = {}
temp_sim = {}	
for case in case_dir:
	os.chdir("case-"+str(case))
	f = open('../Data/Simulations/sim_data_case-'+str(case)+'.lst','w')
	data_sheet = data_management.generate_target_value_tables(FlameMaster_Execution_location, target_list, case, fuel,sim_type)
	temp_sim[str(case)] = data_sheet
	f.write(data_sheet)
	f.close()
	os.chdir(sensDir)
sim_dict[sim_type] = temp_sim

temp_rs = {}	
response_surface_dict = {}
for k,case in enumerate(target_list):
	#print(case)
	case.create_response_surface(activeParameters,unsrt_data,1)
	temp_rs[str(k)] = case.resCoef
	s_a = []
	s_n = []
	s_ea = []
	count = 1
	#print(len(case.resCoef[1:]))
	for i in range(len(case.resCoef[1:3*len(reaction_index)])):
		if count<=len(case.resCoef[1:3*len(reaction_index)]):
			#print(count)
			s_a.append(case.resCoef[count])
			s_n.append(case.resCoef[count+1])
			s_ea.append(case.resCoef[count+2])
			count+=3
	fig = plt.figure()
	y_pos = range(0,len(s_a))
	#print(y_pos)
	plt.barh(y_pos, s_a, align='center', alpha=0.5)
	plt.yticks(y_pos, reaction_index)
	plt.xlabel('Sensitivity of pre-exponential factor (A)')
	plt.title('Sensitivity Analysis using Response surface method')
	plt.savefig('./Plots/sensitivity_A_'+str(target_list.index(case))+'.png')
	plt.close()
	
	fig = plt.figure()
	y_pos = range(0,len(s_n))
	plt.barh(y_pos, s_n, align='center', alpha=0.5)
	plt.yticks(y_pos, reaction_index)
	plt.xlabel('Sensitivity of temperature exponent (n)')
	plt.title('Sensitivity Analysis using Response surface method')
	plt.savefig('./Plots/sensitivity_n_'+str(target_list.index(case))+'.png')
	plt.close()
	
	fig = plt.figure()
	y_pos = range(0,len(s_ea))
	plt.barh(y_pos, s_ea, align='center', alpha=0.5)
	plt.yticks(y_pos, reaction_index)
	plt.xlabel('Sensitivity of Activation Energy (Ea)')
	plt.title('Sensitivity Analysis using Response surface method')
	plt.savefig('./Plots/sensitivity_Ea_'+str(target_list.index(case))+'.png')
	plt.close()
	
	sorted_Params = []
	Params = case.resCoef[1:]
	Max_param = max(abs(np.asarray(Params)))
	criteria = 0.001
	index = []
	for i in Params:
		if i>criteria:
			index.append(case.resCoef.index(i))
	
	#print(index)		
response_surface_dict[sim_type]= temp_rs
os.chdir("..")

if "Original" not in os.listdir():
	os.mkdir("Original")
	os.chdir("Original")
	os.mkdir("Data")
	os.chdir("Data")
	os.mkdir("NumericalAnalysis")
	os.mkdir("ResponseSurface")
	os.mkdir("Simulations")
	os.chdir("..")
	os.mkdir("Plots")
	os.chdir("Plots")
	os.mkdir("SingularValues")
	os.chdir("..")
	testDir = os.getcwd()
	
else:
	os.chdir("Original")
	testDir = os.getcwd()

sim_type = 'Original'
if os.path.isfile("progress") == False:
	FlameMaster_Execution_location , original_manipulation_dict  = simulation_manager.SM(case_dir,rps_order,activeParameters, reaction_index,fallOffCurve_index,thirdBody_index,thermo_index,transport_index, mech_file_location,fileType, rxnUnsrt_data, focUnsrt_data, tbdUnsrt_data, thermoUnsrt_data, transportUnsrt_data, target_list, fuel, global_reaction, thermo_file_location, trans_file_location,startProfile_location,design_type,sim_type,parallel_threads).make_directories_for_simulation()
	locations = open(testDir+"/locations",'w')
	mani_list = open(testDir+"/manipulation_list",'w')
	mani_key  = open(testDir+"/manipulation_key",'w')
	for i in sa_manipulation_dict:
		mani_key.write(i+'\n')
	mani_list.write(str(original_manipulation_dict))
	mani_key.close()
	mani_list.close()
	for i in FlameMaster_Execution_location:
		locations.write(i+"\n")
	locations.close()
	FlameMaster_in_parallel.run_FlameMaster_parallel(FlameMaster_Execution_location, parallel_threads, thermo_file_location, trans_file_location,startProfile_location,file_specific_input)
else:
	original_manipulation_dict={}
	manipulation_list = open(testDir+"/manipulation_list",'r').read().replace("\'","\"")
	original_manipulation_dict = json.loads(manipulation_list)
	#print(manipulation_list)
	#manipulation_list = filter_list(manipulation_list)
	#manipulation_key = open(testDir+"/manipulation_key",'r').readlines()
	#for i,key in enumerate(manipulation_key):
	#	original_manipulation_dict[str(key).strip()] = dict(manipulation_list[i].replace('"',"").strip('\n'))
	progress = open(testDir+"/progress",'r').readlines()
	FlameMaster_Execution_location = open(testDir+"/locations",'r').readlines()
	missing_location = data_management.find_missing_location(FlameMaster_Execution_location, progress)
	FlameMaster_in_parallel.run_FlameMaster_parallel(missing_location, parallel_threads, thermo_file_location, trans_file_location,startProfile_location,file_specific_input)

manipulation_dict[sim_type] = original_manipulation_dict
temp_sim_original = {}
for case in case_dir:	
	os.chdir("case-"+str(case))
	f = open('../Data/Simulations/sim_data_case-'+str(case)+'.lst','w')
	data_sheet = data_management.generate_target_value_tables(FlameMaster_Execution_location, target_list, case, fuel,sim_type)
	temp_sim_original[str(case)] = data_sheet
	f.write(data_sheet)
	f.close()
	os.chdir(testDir)
sim_dict[sim_type] = temp_sim_original		
os.chdir("..")

########################

#################################################################################
###		        Generate Directories                          ###########
###		        and mechanism files 		              ###########
### 		        for FlameMaster    		              ###########
#################################################################################

if "Opt" not in os.listdir():
	os.mkdir("Opt")
	os.chdir("Opt")
	optDir = os.getcwd()
	os.mkdir("Data")
	os.chdir("Data")
	os.mkdir("NumericalAnalysis")
	os.mkdir("ResponseSurface")
	os.mkdir("Simulations")
	os.chdir("..")
	os.mkdir("Plots")
	os.chdir("Plots")
	os.mkdir("SingularValues")
	os.chdir("..")
else:
	os.chdir("Opt")
	optDir = os.getcwd()


print("Generate Directories and mechanism files for Optimization\n")
sim_type = "Opt"
if os.path.isfile("progress") == False:
	FlameMaster_Execution_location , opt_manipulation_dict  = simulation_manager.SM(case_dir,rps_order,activeParameters, reaction_index,fallOffCurve_index,thirdBody_index,thermo_index,transport_index, mech_file_location,fileType, rxnUnsrt_data, focUnsrt_data, tbdUnsrt_data, thermoUnsrt_data, transportUnsrt_data, target_list, fuel, global_reaction, thermo_file_location, trans_file_location,startProfile_location,design_type,sim_type,parallel_threads).make_directories_for_simulation()
	locations = open(optDir+"/locations",'w')
	mani_list = open(optDir+"/manipulation_list",'w')
	mani_key  = open(optDir+"/manipulation_key",'w')
	for i in opt_manipulation_dict:
		mani_key.write(i+'\n')
	mani_list.write(str(opt_manipulation_dict))
	mani_key.close()
	mani_list.close()
	for i in FlameMaster_Execution_location:
		locations.write(i+"\n")
	locations.close()
	FlameMaster_in_parallel.run_FlameMaster_parallel(FlameMaster_Execution_location, parallel_threads, thermo_file_location, trans_file_location,startProfile_location,file_specific_input)

else:
	opt_manipulation_dict = {}
	manipulation_list = open(optDir+"/manipulation_list",'r').read().replace("\'","\"")
	opt_manipulation_dict = json.loads(manipulation_list)
	#print(manipulation_list)
	#manipulation_list = filter_list(manipulation_list)
	#manipulation_key = open(optDir+"/manipulation_key",'r').readlines()
	#for i,key in enumerate(manipulation_key):
	#	opt_manipulation_dict[str(key).strip("\n")] = dict(manipulation_list[i].replace('"',"").strip('\n').strip('{').strip('}'))
	progress = open(optDir+"/progress",'r').readlines()
	FlameMaster_Execution_location = open(optDir+"/locations",'r').readlines()
	missing_location = data_management.find_missing_location(FlameMaster_Execution_location, progress)
	FlameMaster_in_parallel.run_FlameMaster_parallel(missing_location, parallel_threads, thermo_file_location, trans_file_location,startProfile_location,file_specific_input)

manipulation_dict[sim_type] = opt_manipulation_dict
temp_sim_opt = {}
for case in case_dir:	
	os.chdir("case-"+str(case))
	f = open('../Data/Simulations/sim_data_case-'+str(case)+'.lst','w')
	data_sheet = data_management.generate_target_value_tables(FlameMaster_Execution_location, target_list, case, fuel,sim_type)
	temp_sim_opt[str(case)] = data_sheet
	f.write(data_sheet)
	f.close()
	os.chdir(optDir)		
sim_dict[sim_type] = temp_sim_opt

############################################
# 					  					   #	       
#	RESPONSE SURFACE DEVELOPMENT           #
#	and Testing	 		   				   #
#					     				   #
############################################

temp_rs_opt = {}
string_error = "#case/sim	Traning 	Testing\n"
for k,case in enumerate(target_list):
	case.create_response_surface(activeParameters,unsrt_data,2)
	temp_rs_opt[str(k)] = case.resCoef
	print("Testing the response surface for case-{}\n".format(target_list.index(case)))
	xData, yData = data_management.getTestingData(sensDir,case_dir[target_list.index(case)])
	actual_error = []
	error = []
	Sim_value = []
	res_Surface_Testing = open("./Data/Res_testing_case-"+str(target_list.index(case))+".txt","+w")
	string = ""
	for index,data in enumerate(yData):
		
		actual_error.append(((case.calculated_target_value(np.asarray(xData[index]))-data)/data)*100)
		temp_relative = abs((case.calculated_target_value(np.asarray(xData[index]))-data)/data)*100
		actual_value = case.calculated_target_value(np.asarray(xData[index]))
		Sim_value.append(actual_value)
		error.append(abs((case.calculated_target_value(np.asarray(xData[index]))-data)/data)*100)
		string +="{},{},{}\n".format(data,actual_value,temp_relative)
	res_Surface_Testing.write(string)
	MaxError = max(error)
	fig = plt.figure()
	plt.xlabel("Response Surface estimation")
	plt.ylabel("FlameMaster Simulation")
	plt.title("Parity plot: \nshowing error distribution in Response Surface\n testing and traning")
	plt.xlabel("FlameMaster Simulations of Ignition Delay times ($\tau$)")
	plt.ylabel("Response Surface estimation of Ignition Delay times ($\tau$)")
	plt.plot(np.asarray(yData),np.asarray(Sim_value),"go",label="Simulations")
	x = np.linspace(-5,5,500)
	plt.plot(x,x,"-",label="Parity Line")
	plt.legend()
	plt.savefig('Plots/Parity_plot_case_'+str(target_list.index(case))+'.png')

	h = list(actual_error)
	h.sort()
	hmean = np.mean(h)
	hstd = np.std(h)
	pdf = stats.norm.pdf(h, hmean, hstd)
	fig = plt.figure()
	plt.plot(h, pdf,label="pdf")
	plt.legend()
	plt.savefig('Plots/NormalDist_plot_case_'+str(target_list.index(case))+'.png')
	string_error += "{}/{}\t{}\t{}\n".format(case_dir[target_list.index(case)],error.index(MaxError),case.MaxError*100,MaxError)
response_surface_dict[sim_type] = temp_rs_opt
error_file = open("./Max_error.txt","w")
error_file.write(string_error)	
error_file.close()
os.chdir("..")

####################################################################################
####									############
####  Build the objective function and perform scipy.optimize routine.!!!!!!!!!!!!!!
####									############
####################################################################################


def obj_function(x):
	obj = 0.0
	global target_list
	for case in target_list:
		if case.target == "Tig":
			obj += case.d_weight*((case.calculated_target_value(x) - case.observed)/(case.std_dvtn))**2
		elif case.target == "Fsl":
			obj += case.d_weight*((case.calculated_target_value(x) - case.observed)/(case.std_dvtn))**2
		elif case.target == "Scp":
			obj += case.d_weight*((case.calculated_target_value(x) - case.observed)/(case.std_dvtn))**2
	#for i in x:
	#	obj+=9*i**2
	return obj

# Using scipy.optimize
var = 3*len(reaction_index)+4*len(fallOffCurve_index)+len(thirdBody_index)+7*len(thermo_index)+2*len(transport_index)

init_guess = np.zeros(var)
#print("\n\nAlgorithm used for optimization : {}\n\n".format(opt.get_algorithm_name()))
t = time.time()
b = (-1.0,1.0)
bnd = []
for index in range(var):
	bnd.append(b)
bnds = tuple(bnd)
opt = minimize(obj_function,init_guess,bounds=bnds)

dt = int(time.time() - t)
hours = dt/3600
minutes = (dt%3600)/60
seconds = dt%60
print("Time for performing Optimization: {h} hours,  {m} minutes, {s} seconds\n................................................ ".format(h = hours, m = minutes, s =seconds))
print(">>>>>>>>>>>>>>>\n\nOptimized Vectors\n\n>>>>>>>>>>>>>>>>>")
z_list = []
for i in reaction_index:
	z_list.append(i+"_a")
	z_list.append(i+"_n")
	z_list.append(i+"_e")

for i in fallOffCurve_index:
	z_list.append(i+"_alpha")
	
for i in thirdBody_index:
	z_list.append(i)
for i in thermo_index:
	z_list.append(i+"_a1")
	z_list.append(i+"_a2")
	z_list.append(i+"_a3")
	z_list.append(i+"_a4")
	z_list.append(i+"_a5")
	z_list.append(i+"_a6")
	z_list.append(i+"_a7")
for i in transport_index:
	z_list.append(i+"_LJe")
	z_list.append(i+"_LJs")
for i, j in enumerate(z_list):
	print("\n{}\t{}".format(j, opt.x[i]))
#for i, j in enumerate(reaction_index):
#	print("\n{}\t{}".format(j, opt.x[i]))
print("\n\n\nInitial objective function value : {}\n".format(obj_function(init_guess)))
print("Optimized objective function value : {}\n".format(obj_function(opt.x)))

####################################################      
########                        	 ###########              
########   	 Post Data Analysis      ###########           
########                        	 ###########              
####################################################       

	
####Build the optimized mechanism!!!!!!!!!!!!!!!!!!!         
MechManipulator = MechanismManipulator.MechanismManipulator(mech_file_location,fileType,thermo_file_location,trans_file_location,reaction_index,fallOffCurve_index,thirdBody_index,thermo_index,transport_index,rxnUnsrt_data, focUnsrt_data,tbdUnsrt_data, thermoUnsrt_data,transportUnsrt_data)
param_opt_dict = MechManipulator.GeneratePerturbedMechanism(target_list,opt.x,sim_type,"True")


#### Posterior covariance matrix

J = []
W = []
Ey = []
dY = []

for case in target_list:
	#print("The index for case-{}\n".format(target_list.index(case)))
	if case.target.strip() == "Tig":
		dY.append(case.calculated_target_value(opt.x) - (case.observed+case.std_dvtn))
		J.append(case.Jacobian(opt.x,2))
		W.append(case.d_weight)
		Ey.append((np.log(case.std_dvtn))**2)
	elif case.target.strip() == "Fsl":
		dY.append(case.calculated_target_value(opt.x) - case.observed)
		J.append(case.Jacobian(opt.x,2))
		W.append(case.d_weight)
		Ey.append(float(1/(np.log(case.std_dvtn))**2))
	elif case.target.strip() == "Scp":
		dY.append(case.calculated_target_value(opt.x) - case.observed)
		J.append(case.Jacobian(opt.x,2))
		W.append(case.d_weight)
		Ey.append(float(1/(case.std_dvtn)**2))

#######################################################################
#####								#######
#####Posterior Cov Method of David Sheen and Turanyi, Nagy et at#######
#####								#######
#######################################################################
Ey = np.matrix(np.diag(np.asarray(Ey)))
#3Ed = np.matrix(np.outer(np.asarray(dY),np.asarray(dY)))
#S = Ed+np.matrix(Ey)
J = np.matrix(J)
#print(np.shape(J))
#print(np.shape(J.T))
#W = np.diag(np.asarray(W))
Ey_ = np.linalg.inv(np.matrix(Ey))
#print("Ed is {}\n".format(Ed))
#print("Ey_ is {}\n".format(Ey_))
#print("J is {}\n".format(J))
#print("W is {}\n".format(W))
#print("S is {}\n".format(S))
#print("Ey is {}\n".format(Ey))
#A_o = np.dot(J.T,np.dot(W,Ey_))
#print("A_o shape is {}\n".format(np.shape(A_o)))
#print("J shape is {}\n".format(np.shape(J)))
#A_j = np.dot(A_o,J)
#print("A_j shape is {}\n".format(np.shape(A_j)))
#print("A_o is {}\n".format(A_o))
#A_o_ = np.linalg.inv(A_j)
#B_o = np.dot(A_o_,A_o)
#cov = np.linalg.inv(np.dot(B_o,np.dot(S,B_o.T)))
#posterior_cholesky = np.linalg.cholesky(cov)
cov_inverse = np.dot(J.T,np.dot(Ey_,J)) + np.identity(len(opt.x),dtype=float)
cov = np.linalg.inv(cov_inverse)
posterior_cholesky = np.linalg.cholesky(cov)
#print("shape of cov is  {}\n".format(np.shape(posterior_cov)))
#posterior_cholesky = np.linalg.cholesky(posterior_cov)
#print("Cov has shape {}\n".format(shape(cov)))
#print("B_o is {}\n".format(B_o))x

#print("cov is {}\n".format(cov))
#print("cholesky is {}\n".format(posterior_cholesky.T))
unsrtPosterior = {}
count = 3*len(reaction_index)
pcov_rxn = plotter.extract_block_diag(posterior_cholesky[0:count,0:count],M=3)
for i,rxn in enumerate(reaction_index):
	unsrtPosterior[str(rxn)] = list(pcov_rxn)[i]

pcov_foc = plotter.extract_block_diag(posterior_cholesky[count:count+4*len(fallOffCurve_index),count:count+4*len(fallOffCurve_index)],M=1)
for i,foc in enumerate(fallOffCurve_index):
	unsrtPosterior[str(foc)] = list(pcov_foc)[i]

count=count+len(fallOffCurve_index)
if len(np.asarray(total_m_params)) != 0:
	pcov_m = plotter.extract_block_diag(posterior_cholesky[count:count+len(np.asarray(total_m_params).flatten()),count:count+len(np.asarray(total_m_params).flatten())],M=len(np.asarray(total_m_params).flatten()))
	start = 0
	end = 0
	for i,m in enumerate(thirdBody_index):
		length = thirdBody_dict[m]
		end +=len(length)
		unsrtPosterior[str(m)] = list(pcov_m)[start:end]
		start = end
	#print(unsrtPosterior[str(m)])
	count = count+len(np.asarray(total_m_params).flatten())
if len(thermo_index) != 0:
	pcov_thermo = plotter.extract_block_diag(posterior_cholesky[count:count+7*len(thermo_index),count:count+7*len(thermo_index)],M=7)
	for i,th in enumerate(thermo_index):
		unsrtPosterior[str(th)] = list(pcov_thermo)[i]
	count = count+7*len(thermo_index)
if len(transport_index) != 0:
	pcov_transport = plotter.extract_block_diag(posterior_cholesky[count:count+2*len(transport_index),count:count+2*len(transport_index)],M=2)
	for i,trans in enumerate(transport_index):
		unsrtPosterior[str(trans)] = list(pcov_transport)[i]
#Finding the posterior uncertainty for reactions

#############################################################
### 	      Building maga database 	   					#
###			for parameters and targets						#
#############################################################
#print(manipulation_dict)

parametric_space = {}
for i in activeParameters:
	temp_database = {}
	temp_database["unsrtDatabase"] = unsrtDatabase[str(i)]
	temp_database["sensitivityManipulations"] = manipulation_dict["sa"][str(i)]
	temp_database["optManipulations"] = manipulation_dict["Opt"][str(i)]
	temp_database["originalManipulations"] = manipulation_dict["Original"][str(i)]
	temp_database["optimizedParameter"] = param_opt_dict[str(i)]
	temp_database["posteriorCovariance"] = unsrtPosterior[str(i)]
	parametric_space[str(i)] = temp_database


DataSet_Tig = []
DataSet_Fsl = []
DataSet_Scp = []
target_space = {}
for case in case_dir:
	
	if target_list[case].target == "Tig":
		DataSet_Tig.append(target_list[case].d_set)
	if target_list[case].target == "Fsl":
		DataSet_Fsl.append(target_list[case].d_set)
	if target_list[case].target == "Scp":
		DataSet_Scp.append(target_list[case].d_set)
target_space["Tig"] = list(OrderedDict.fromkeys(DataSet_Tig))
target_space["Fsl"] = list(OrderedDict.fromkeys(DataSet_Fsl))
target_space["Scp"] = list(OrderedDict.fromkeys(DataSet_Scp))

dataSet = {}
#populating dataSet
for d_types in target_space:
	for set_index in target_space[d_types]:
		set_list = []
		for case in case_dir:
			set_data = {}
			if target_list[case].d_set == set_index:
				set_data["Target_database"] = target_list[case]
				set_data["SA_simulations"] = sim_dict["sa"][str(case)]
				set_data["Original_simulations"] = sim_dict["Original"][str(case)]
				set_data["Opt_simulations"] = sim_dict["Opt"][str(case)]
				set_data["SA_PRS"] = response_surface_dict["sa"][str(case)]
				set_data["Opt_PRS"] = response_surface_dict["Opt"][str(case)]
				#set_data[str(case)] = temp_targets
				set_list.append(set_data)
			else:
				continue
		dataSet[str(set_index)] = set_list

#print(dataSet)
parameter_list = []
for i in parametric_space:
	p = combustion_variable_class.combustion_variable(i,parametric_space[i])
	parameter_list.append(p)

target_sets = []
for i in dataSet:
	tar = combustion_dataset_class.combustion_dataset(i,dataSet[i],opt.x)
	target_sets.append(tar)

plotter.plot(activeParameters,parameter_list,case_dir,target_sets)
#plotter.plot_errors(target_list,opt.x)
Theta = []
#for i in reaction_index:
#	T1,T2 = unsrt_data[i].getTempRange()
#	T = np.linspace(T1,T2,1000)
#	theta = []
#	for i in T:
#		Th1 = 1
#		Th2 = np.log(i)
#		Th3 = -1/i
#		theta.append([Th1,Th2,Th3])
#	theta = np.asarray(theta)
#	Theta.append(theta)
#plotter.plot_errors(target_list, opt.x)
#plotter.plot_vector(reaction_index, opt.x)
print("generating log files and optimized mechanism file..... \n\n")
#plotter.plot_graphs(target_list,init_guess,posterior_cholesky,opt.x)
#plotter.plot_rxnUnsrt(mech_file_location,unsrt_location,thermo_file_location,trans_file_location,target_list,sim_type,Theta,Posterior_cov,opt.x,"True")
IFR_unopt = Input_file_reader.MechParsing(mech_file_location)
IFR_opt = Input_file_reader.MechParsing("./mechanism_opt.mech")

for index,rxn_list in enumerate(BranchingRxns):
	unOptRatios = IFR_unopt.getRatioData(rxn_list,"unOpt")
	
	OptRatios = IFR_opt.getRatioData(rxn_list,"Opt")
	
	fig = plt.figure()
	T = np.linspace(500,2500,len(np.asarray(unOptRatios)[:,0]))
	for i in range(len(unOptRatios[0])):
		plt.plot(T,np.asarray(unOptRatios)[:,i],"--")
		plt.plot(T,np.asarray(OptRatios)[:,i],"-")
		plt.xlabel("Temperature (K)")
		plt.ylabel("Branching ratios")
		plt.title("Branching ratios for {} \nbefore and after optimization".format(rxn_list))
		plt.savefig("./BranchRatio/"+str(rxn_list)+".png")
#plotter.print_cov(Posterior_cov)
#plotter.print_cov(pcov_rxn,"reaction")
#plotter.print_cov(pcov_foc,"FoC")
#plotter.print_cov(pcov_hcp,"Hcp")
#plotter.print_cov(pcov_m,"collision_efficiency")
#plotter.print_cov(pcov_enthalpy,"enthalpy")
#plotter.print_cov(pcov_enthalpy,"entropy")

print(">>>>>> Program Exiting <<<<<<")
